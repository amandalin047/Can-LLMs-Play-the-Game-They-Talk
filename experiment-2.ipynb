{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc6f98-62c4-4588-b9ec-a5cfdbc7e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "#from langchain_ollama import ChatOllama\n",
    "#import ollama\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e79bca5-78fc-4536-afea-bf4a09a027e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are playing a single round of a Poker game as player 1 against an opponent (player 2). Here are the game rules:\n",
      "Each player antes 1 chip. Each player is dealt a unique card from a deck consisting of only a Jack (J), a Queen (Q), and a King (K). The third card not dealt is left unseen.\n",
      "Player 1 can check or bet 1 chip.\n",
      "If player 1 checks, player 2 can check or bet 1 chip.\n",
      "  > If player 2 checks, a showdown occurs.\n",
      "  > If player 2 bets, player 1 can fold or call.\n",
      "      > If player 1 folds, player 2 takes the entire pot.\n",
      "      > If player 1 calls, a showdown occurs.\n",
      "If player 1 bets, player 2 can fold or call.\n",
      "  > If player 2 folds, player one takes the entire pot.\n",
      "  > If player 2 calls, a showdown occurs.\n",
      "  The game starts now. Your card is Q. What is your move?  \n",
      "\n",
      "===========================================================================================================\n",
      "\n",
      "You are playing a single round of a Poker game as player 1 against an opponent (player 2). Here are the game rules:\n",
      "Each player antes 1 chip. Each player is dealt a unique card from a deck consisting of only a Jack (J), a Queen (Q), and a King (K). The third card not dealt is left unseen.\n",
      "Player 1 can check or bet 1 chip.\n",
      "If player 1 checks, player 2 can check or bet 1 chip.\n",
      "  > If player 2 checks, a showdown occurs.\n",
      "  > If player 2 bets, player 1 can fold or call.\n",
      "      > If player 1 folds, player 2 takes the entire pot.\n",
      "      > If player 1 calls, a showdown occurs.\n",
      "If player 1 bets, player 2 can fold or call.\n",
      "  > If player 2 folds, player one takes the entire pot.\n",
      "  > If player 2 calls, a showdown occurs.\n",
      "Your oppoent employs the follwoing strategy:  with a K, always bet or call; with a Q, always check after you check, and call with a 1/3 probability after you bet; with a J, always fold after you bet, and bet with a probability of 1/3 after you check. The game starts now. Your card is J. What is your move?  Please provide your choice of action as player 1 in the following format without any explanation: Bet/Check.\n"
     ]
    }
   ],
   "source": [
    "inform_llm_of_opponent_strategy = \"Your oppoent employs the follwoing strategy: \"\n",
    "\n",
    "nash = \"with a K, always bet or call; with a Q, always check after you check, and call with a 1/3 probability after you bet; with a J, always fold after you bet, and bet with a probability of 1/3 after you check.\"\n",
    "copy_player1 = \"always call after you bet, and always check after you check.\"\n",
    "random = \"choose an action at random with equal probability.\"\n",
    "\n",
    "#format_instruction_explain_after = \"Please first output your choice of action as player 1 in the following format: Bet/Check, then explain your choice.\"\n",
    "cot_instruction = \"Think step by step:\\n- What could your opponent's card be?\\n- Determine the pot size and calculate the net gain or loss considering each player's contribution to the pot.\\n- Evaluate the expected payoff for each strategy player 1 can adopt.\"\n",
    "format_instruction_no_explain=\"Please provide your choice of action as player 1 in the following format without any explanation: Bet/Check.\"\n",
    "\n",
    "def generate_prompt(llm_card,\n",
    "                    inform_llm_of_opponent_strategy=\"\",\n",
    "                    strategy_description=\"\",\n",
    "                    cot_instruction=\"\",\n",
    "                    format_instruction=\"\"):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are playing a single round of a Poker game as player 1 against an opponent (player 2). Here are the game rules:\n",
    "Each player antes 1 chip. Each player is dealt a unique card from a deck consisting of only a Jack (J), a Queen (Q), and a King (K). The third card not dealt is left unseen.\n",
    "Player 1 can check or bet 1 chip.\n",
    "If player 1 checks, player 2 can check or bet 1 chip.\n",
    "  > If player 2 checks, a showdown occurs.\n",
    "  > If player 2 bets, player 1 can fold or call.\n",
    "      > If player 1 folds, player 2 takes the entire pot.\n",
    "      > If player 1 calls, a showdown occurs.\n",
    "If player 1 bets, player 2 can fold or call.\n",
    "  > If player 2 folds, player one takes the entire pot.\n",
    "  > If player 2 calls, a showdown occurs.\n",
    "{inform_llm_of_opponent_strategy} {strategy_description} The game starts now. Your card is {llm_card}. What is your move? {cot_instruction} {format_instruction}\"\"\"\n",
    "          \n",
    "    return prompt\n",
    "\n",
    "print(generate_prompt(\"Q\",\n",
    "                      inform_llm_of_opponent_strategy=\"\",\n",
    "                      strategy_description=\"\",\n",
    "                      cot_instruction=\"\",\n",
    "                      format_instruction=\"\"))\n",
    "print(\"\\n===========================================================================================================\")\n",
    "print(generate_prompt(\"J\",\n",
    "                      inform_llm_of_opponent_strategy=inform_llm_of_opponent_strategy,\n",
    "                      strategy_description=nash,\n",
    "                      cot_instruction=\"\",\n",
    "                      format_instruction=format_instruction_no_explain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "455b1626-bd81-4fb3-a90a-32ca64a5bef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#models_to_test = [\"gpt-4-turbo\", \"gpt-4o\", \"o3-mini\"]\n",
    "#models_to_test = [\"o3-mini\"]\n",
    "\n",
    "# gpt-4-turbo\n",
    "    # K: bet*5\n",
    "    # Q: bet*4, check*1\n",
    "    # J: check*5\n",
    "\n",
    "# gpt-4-turbo\n",
    "    # K: bet*5\n",
    "    # Q: bet*4, check*1\n",
    "    # J: check*5\n",
    "\n",
    "llm_card_list = [\"K\", \"Q\", \"J\"]\n",
    "strategy_descriptions = [random, copy_player1, nash]\n",
    "\n",
    "client =openai.OpenAI()\n",
    "def get_llm_response(model, prompt, temp=0.2):\n",
    "    if model[0] != \"o\":\n",
    "        response = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                    }\n",
    "                    ],\n",
    "                    model=model,\n",
    "                    temperature=temp,\n",
    "                    logprobs=True\n",
    "                )\n",
    "    else:\n",
    "        response = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                    }\n",
    "                    ],\n",
    "                    model=model,\n",
    "                )    \n",
    "    print(response.choices[0].message.content)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f348538",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/log-files/exp-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce21acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_A = \"LLMs-responses-A.txt\"\n",
    "\n",
    "models_to_test, temps = [\"gpt-4-turbo\", \"gpt-4o\"], [0.2, 0.8]\n",
    "for model in models_to_test:\n",
    "    for temp in temps:\n",
    "        print(f\"**Testing model {model} @ temp = {temp}**\")\n",
    "        with open(file_A, \"a\") as f:\n",
    "            f.write(f\"Testing model {model} @ temp = {temp}\")\n",
    "        for llm_card in llm_card_list:\n",
    "            print(f\"  < Card is {llm_card} >\")\n",
    "            with open(file_A, \"a\") as f:\n",
    "                f.write(f\"  \\n< Card is {llm_card} >\")\n",
    "            prompt = generate_prompt(llm_card,\n",
    "                                 inform_llm_of_opponent_strategy=\"\",\n",
    "                                 strategy_description=\"\",\n",
    "                                 cot_instruction=\"\",\n",
    "                                 format_instruction=\"\")\n",
    "            for _ in range(5):\n",
    "                print(f\"    Trial {_+1}:\")\n",
    "                response = get_llm_response(model, prompt, temp=temp)\n",
    "                with open(file_A, \"a\") as f:\n",
    "                    f.write(f\"\\n    Trial {_+1}:\")\n",
    "                    f.write(f\"\\n    {response.choices[0].message.content}\")\n",
    "        print(\"\\n===========================================================================================================\") \n",
    "        with open(file_A, \"a\") as f:\n",
    "            f.write(\"\\n===============\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c0294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_to_test = [\"o3-mini\", \"o3\", \"o1\", \"o4-mini\"]\n",
    "models_to_test = [\"o3-mini\"]\n",
    "for model in models_to_test:\n",
    "    print(f\"**Testing model {model}**\")\n",
    "    with open(file_A, \"a\") as f:\n",
    "        f.write(f\"Testing model {model}\")\n",
    "    for llm_card in llm_card_list:\n",
    "        print(f\"  < Card is {llm_card} >\")\n",
    "        with open(file_A, \"a\") as f:\n",
    "            f.write(f\"  \\n< Card is {llm_card} >\")\n",
    "        prompt = generate_prompt(llm_card,\n",
    "                                 inform_llm_of_opponent_strategy=\"\",\n",
    "                                 strategy_description=\"\",\n",
    "                                 cot_instruction=\"\",\n",
    "                                 format_instruction=\"\")\n",
    "        for _ in range(5):\n",
    "            print(f\"    Trial {_+1}:\")\n",
    "            response = get_llm_response(model, prompt)\n",
    "            with open(file_A, \"a\") as f:\n",
    "                f.write(f\"\\n    Trial {_+1}:\")\n",
    "                f.write(f\"\\n    {response.choices[0].message.content}\")\n",
    "    print(\"\\n===========================================================================================================\") \n",
    "    with open(file_A, \"a\") as f:\n",
    "        f.write(\"\\n===============\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ddf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_B = \"LLMs-responses-B.txt\"\n",
    "\n",
    "models_to_test = [\"gpt-4-turbo\", \"gpt-4o\"]\n",
    "for model in models_to_test:\n",
    "    for temp in temps:\n",
    "        print(f\"**Testing model {model} @ temp = {temp}**\")\n",
    "        with open(file_B, \"a\") as f:\n",
    "            f.write(f\"Testing model {model} @ temp = {temp}\")\n",
    "        for llm_card in llm_card_list:\n",
    "            print(f\"  < Card is {llm_card} >\")\n",
    "            with open(file_B, \"a\") as f:\n",
    "                f.write(f\"  \\n< Card is {llm_card} >\")\n",
    "            for strategy in strategy_descriptions:\n",
    "                print(f\"    < Strategy: {strategy} >\")\n",
    "                with open(file_B, \"a\") as f:\n",
    "                    f.write(f\"\\n    < Strategy: {strategy} >\")          \n",
    "                prompt = generate_prompt(llm_card,\n",
    "                                 inform_llm_of_opponent_strategy=inform_llm_of_opponent_strategy,\n",
    "                                 strategy_description=strategy,\n",
    "                                 cot_instruction=\"\",\n",
    "                                 format_instruction=\"\")\n",
    "            \n",
    "                response = get_llm_response(model, prompt, temp=temp)\n",
    "                with open(file_B, \"a\") as f:\n",
    "                    f.write(f\"\\n    {response.choices[0].message.content}\")\n",
    "        print(\"\\n===========================================================================================================\") \n",
    "        with open(file_B, \"a\") as f:\n",
    "            f.write(\"\\n===============\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d005ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**Testing model o3-mini**\")\n",
    "with open(file_B, \"a\") as f:\n",
    "    f.write(f\"Testing model o3-mini\")\n",
    "for llm_card in llm_card_list:\n",
    "    print(f\"  < Card is {llm_card} >\")\n",
    "    with open(file_B, \"a\") as f:\n",
    "        f.write(f\"  \\n< Card is {llm_card} >\")\n",
    "    for strategy in strategy_descriptions:\n",
    "        print(f\"    < Strategy: {strategy} >\")\n",
    "        with open(file_B, \"a\") as f:\n",
    "            f.write(f\"\\n    < Strategy: {strategy} >\")   \n",
    "        prompt = generate_prompt(llm_card,\n",
    "                                     inform_llm_of_opponent_strategy=inform_llm_of_opponent_strategy,\n",
    "                                     strategy_description=strategy)\n",
    "        response = get_llm_response(\"o3-mini\", prompt)\n",
    "        with open(file_B, \"a\") as f:\n",
    "            f.write(f\"\\n    {response.choices[0].message.content}\")\n",
    "print(\"\\n===========================================================================================================\") \n",
    "with open(file_B, \"a\") as f:\n",
    "    f.write(\"\\n===============\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_C = \"LLMs-responses-C.txt\"\n",
    "\n",
    "models_to_test = [\"gpt-4-turbo\", \"gpt-4o\"]\n",
    "for model in models_to_test:\n",
    "    for temp in temps:\n",
    "        print(f\"**Testing model {model} @ temp = {temp}**\")\n",
    "        with open(file_C, \"a\") as f:\n",
    "            f.write(f\"Testing model {model} @ temp = {temp}\")\n",
    "        for llm_card in llm_card_list:\n",
    "            print(f\"  < Card is {llm_card} >\")\n",
    "            with open(file_C, \"a\") as f:\n",
    "                f.write(f\"  \\n< Card is {llm_card} >\")\n",
    "            for strategy in strategy_descriptions:\n",
    "                print(f\"    < Strategy: {strategy} >\")\n",
    "                with open(file_C, \"a\") as f:\n",
    "                    f.write(f\"\\n    < Strategy: {strategy} >\")          \n",
    "                prompt = generate_prompt(llm_card,\n",
    "                                 inform_llm_of_opponent_strategy=inform_llm_of_opponent_strategy,\n",
    "                                 strategy_description=strategy,\n",
    "                                 cot_instruction=cot_instruction,\n",
    "                                 format_instruction=\"\")\n",
    "            \n",
    "                response = get_llm_response(model, prompt, temp=temp)\n",
    "                with open(file_C, \"a\") as f:\n",
    "                    f.write(f\"\\n    {response.choices[0].message.content}\")\n",
    "        print(\"\\n===========================================================================================================\") \n",
    "        with open(file_C, \"a\") as f:\n",
    "            f.write(\"\\n===============\\n\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
